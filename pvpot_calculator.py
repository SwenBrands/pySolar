#!/usr/bin/env python

'''Retains reanalysis data at the grid-boxes located nearest to the AEMET station data, that was read-in and ordered by csv2nc.py in a previous working step.
Hourly reanlaysis data is aggregated to daily-mean values as indicated by the <temporal_aggregation> attribute defined below.
Author: Swen Brands, brandssf@ifca.unican.es
'''

#load packages
import numpy as np
import dask
import xarray as xr
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cf
import os
import pandas as pd
import xskillscore as xs
from math import radians, cos, sin, asin, sqrt #needed to calculate haversine distance
home = os.getenv('HOME')
exec(open('functions_radiation.py').read())
exec(open(home+'/datos/tareas/proyectos/pticlima/seasonal/python/functions_seasonal.py').read())

#set input parameters
model_dataset = 'era5_land'
rundir = home+'/datos/tareas/proyectos/pticlima/pyPTIclima/pySolar' #script directory, you should be there or point to this directory when running these scripts via python
dir_rean = home+'/datos/OBSData/era5_land_javi' #path to reanalysis data used for calculating the pv index; base directory structure similar to data, will be expanded as a function of the target area (Spain or Canaries) and year
#dir_rean = '/media/swen/ext_disk2/datos/OBSdata/era5_land'
dir_rean_disagg = home+'/datos/OBSData/era5_land_isagg'
dir_netcdf = home+'/datos/tareas/proyectos/pticlima/radiation/results/data/pvpot' #path to output netcdf file generated by this script
dir_figs = home+'/datos/tareas/proyectos/pticlima/radiation/figs/validation' #path to output figures file generated by this script
taryears = [1980,2021] #start and end years used for validation
variable = ['u10','v10','ssrd','t2m'] #variable names used to calculate pv index, in fixed order!
domain = 'Spain'
varname_out = 'pvpot' #variable name of the photovoltaic potential index within the output netcdf file covering the whole <taryears> period. This file is stored in the <dir_netcdf> folder.
corr_radiation = 'yes' #correct input global shortwave radiation data; yes or no
solar_constant = 1362. #in W/m2 upper threshold of the global shortwave radiation data, values above this threshold in the dataset are set to this threshold.
darkness = 0. #in W/m2 lower threshold of the global shortwave radiation data, values below this threshold in the dataset are set to this threshold.

precision = 'float32' #precision of the variable in the output netCDF files
dpival = 300 #resultion of the output figure in dpi
figformat = 'pdf' #format of the output figures: pdf, png, etc.
colormap = 'Spectral_r'

##EXECUTE ##############################################################
#create auxiliary directory where the yearly pvpot files are stored in a first step and thereafter loaded to generate a single netCDF file in <dir_netcdf>; add code to erase these auxiliary file each time the script is run in future versions.
aux_dir = dir_netcdf+'/aux'
if os.path.isdir(aux_dir) != True:
    os.makedirs(aux_dir)
years = np.arange(taryears[0],taryears[1]+1)

for yy in np.arange(len(years)):
    print('Calculating PV potential for '+str(years[yy])+'...')
    listdir_u10 = get_nc_path(years[yy],domain,dir_rean,variable[0])
    listdir_v10 = get_nc_path(years[yy],domain,dir_rean,variable[1])
    listdir_ssrd = get_nc_path(years[yy],domain,dir_rean,variable[2])
    listdir_t2m = get_nc_path(years[yy],domain,dir_rean,variable[3])
    print('The following files will be loaded for the year '+str(years[yy])+' and domain '+domain+'...')
    print(listdir_u10)
    print(listdir_v10)
    print(listdir_ssrd)
    print(listdir_t2m)

    print('Obtaining hourly wind speed from '+variable[0]+' and '+variable[1]+' for the year '+str(years[yy]))
    nc_u10 = xr.open_mfdataset(listdir_u10) #data from ERA5-Land is in m/s as required for pv index calculation; see doi:10.1016/j.energy.2006.12.006
    nc_v10 = xr.open_mfdataset(listdir_v10)
    nc_si10 = np.sqrt(nc_u10[variable[0]]**2 + nc_v10[variable[1]]**2).rename('si10')
    #close u10 and v10 xarray object to save memory
    nc_u10.close()
    nc_v10.close()
    del(nc_u10,nc_v10)
    nc_ssrd = xr.open_mfdataset(listdir_ssrd)
    #nc_ssrd[variable[2]] = nc_ssrd[variable[2]]/3600 #converts ERA5-Land data form hourly accumulation in W/m2 to W/m2 (per second) as required for pv index calculation; see in doi:10.1016/j.energy.2006.12.006
    nc_ssrd = nc_ssrd[variable[2]]/3600 #converts ERA5-Land data form hourly accumulation in W/m2 to W/m2 (per second) as required for pv index calculation; see in doi:10.1016/j.energy.2006.12.006
    print('The nan percentage, minimum, mean and maximum hourly '+variable[2]+' values from '+model_dataset+' in '+str(years[yy])+' over '+domain+' are:')
    print(np.round(np.sum(np.isnan(nc_ssrd)).values/nc_ssrd.size*100,4))
    print(np.round(nc_ssrd.min().values,2))
    print(np.round(nc_ssrd.mean().values,2))
    print(np.round(nc_ssrd.max().values,2))
    #optionally correct the radiation data
    if corr_radiation == 'yes':
        print('Raw '+variable[2]+' data is corrected with '+str(solar_constant)+' and '+str(darkness)+' W/m2 threshold values to correct extensively large and slightly negative values in '+model_dataset+', respectively.')
        np_ssrd = nc_ssrd.values
        darkmask = np.where(np_ssrd < darkness)
        sc_mask = np.where(np_ssrd > solar_constant)
        np_ssrd[darkmask] = darkness
        np_ssrd[sc_mask] = solar_constant
        nc_ssrd.values = np_ssrd
    nc_t2m = xr.open_mfdataset(listdir_t2m)
    #nc_t2m[variable[3]] = nc_t2m[variable[3]]-273.15 #convert ERA5-Land data from Kelvin to degrees Celsius
    nc_t2m = nc_t2m[variable[3]]-273.15 #convert ERA5-Land data from Kelvin to degrees Celsius
    #create pandas Datetime indices and retain commmon period
    dates = pd.DatetimeIndex(nc_si10.time.values)
    
    #The input variables are now ready for PV index calculation following doi:10.1016/j.energy.2006.12.006 and 10.1038/ncomms10014
    print('Calculating hourly Photovoltaic Potential Index for the year '+str(years[yy])+' following Chennie et al. 2017, doi:10.1016/j.energy.2006.12.006 and Jerez et al. 2015, doi:10.1038/ncomms10014')
    tcell = nc_t2m*0.943 + nc_ssrd*0.028 - nc_si10*1.528 + 4.3 #as defined in doi:10.1016/j.energy.2006.12.006 on page 1728
    pr = 1 - 0.005 * (tcell - 25) #as defined in doi:10.1016/j.energy.2006.12.006 on page 6, an alternative value for beta = 0.005 is 0.0045, see Crook et al. 2011, doi:10.1039/C1EE01495A 
    pv = pr*nc_ssrd/1000 #as defined in doi:10.1016/j.energy.2006.12.006 on page 6
    pv = pv.rename(varname_out)
    savename = aux_dir+'/pvpot_'+model_dataset+'_'+domain+'_'+str(years[yy])+'.nc'
    pv.to_netcdf(savename)
    
    #close all loop-wise xarray object
    nc_si10.close()
    nc_ssrd.close()
    nc_t2m.close()
    del(nc_si10,nc_ssrd,nc_t2m)

#then load all the newly generated yearly files and store them in a single, definite netCDF file with approriate metadata
print('Loading the newly generated yearly files and store them in a single, definite netCDF file with approriate metadata...')
filename_pvpot_in = aux_dir+'/pvpot_'+model_dataset+'_'+domain+'*.nc'
nc_pv = xr.open_mfdataset(filename_pvpot_in)
nc_pv.attrs['standard_name'] = varname_out
nc_pv.attrs['long_name'] = 'photovoltaic potential index under all-sky conditions'
nc_pv.attrs['units'] = 'Positive dimensionless'
nc_pv.attrs['dataset'] = model_dataset
nc_pv.attrs['outlier_correction'] = corr_radiation+', if set to yes, the minimum and maximum '+variable[2]+' values underlying '+varname_out+' are limited by darkness set at '+str(darkness)+' and the solar constant at the top of the atmosphere set at '+str(solar_constant)+' W/m2'
nc_pv.attrs['description'] = 'Photovoltaic potential index describing the cells potential production with respect to the fixed production for of a global downward shortwave radiation of 1000 W/m2. Positive values indicate a better production than this norm.'
nc_pv.attrs['formulae'] = varname_out+' = pr*ssrd/ssrd_r, where ssrd is the actual (i.e. taken from '+model_dataset+' hourly global downward shortwave radiation at the surface in W/m2, ssrd_r is the respective reference radiation set at 1000 W/m2, with pr = 1 - beta * (tcell - Ta), with tcell = t2m*c1 + ssrd*c2 - si10*c3 + c4; pr is the so-called performance ratio, beta = 0.005 is a temperature coefficient related to the cell material and structure, Ta is the reference air temperature set at 25ºC, t2m is the actual hourly surface air temperature in degrees Celsius, si10 is the actual sustained surface wind speed in m/s and c1 = 0.943, c2 = 0.028, c3 = 1.528 and c4 = 4.3 are coefficients that depend on details of the module and mounting that affect heat transfer from the cell, see doi:10.1039/c1ee01495a for more information'
nc_pv.attrs['cell_material'] = 'This index if valid for monocrystalline silicon solar panels'
nc_pv.attrs['references'] = 'Chennie et al. 2017, doi:10.1016/j.energy.2006.12.006 and Jerez et al. 2015, doi:10.1038/ncomms10014'
nc_pv.attrs['author'] = 'Swen Brands, brandssf@ifcan.unican.es or swen.brands@gmail.com'
nc_pv.attrs['funding'] = 'This work is funded by the Ministry for the Ecological Transition and the Demographic Challenge (MITECO) and the European Commission NextGenerationEU (Regulation EU 2020/2094), through CSIC’s Interdisciplinary Thematic Platform Clima (PTI-Clima)'
start_date = str(nc_pv.time.values[0]).replace('-','').replace(':','')[0:-14]
end_date = str(nc_pv.time.values[-1]).replace('-','').replace(':','')[0:-14]
savename_pvpot_out = dir_netcdf+'/pvpot_1h_'+model_dataset+'_'+domain+'_'+start_date+'_'+end_date+'.nc'
nc_pv.to_netcdf(savename_pvpot_out)
nc_pv.close()
del(nc_pv)

print('INFO: pvpot_calculator.py has been run successfully! A new output netCDF file has been created in '+savename_pvpot_out)

    # #load and disaggregate CDS ssrd data from 24-hour accumulations to hourly accumulations
    # nc_ssrd = xr.open_mfdataset(listdir_ssrd)
    # nc_ssrd_orig = nc_ssrd.copy(deep=True) # make a copy of the original aggegeated xr data array
    # nc_ssrd = disaggregate_rean(nc_ssrd,variable[2])
    
    #nc_ca_clim = nc_ca[variable].groupby('time.hour').mean('time',skipna=True)



#plt.plot(nc_ca_clim.values[:,4,50])

# #save disaggregated data, if necessary
# start_time_aux = str(dates_ca.min()).replace('-','').replace(' ','').replace(':','')[0:-6]
# end_time_aux = str(dates_ca.max()).replace('-','').replace(' ','').replace(':','')[0:-6]
# savename_disagg = dir_rean_disagg+'/'+model_dataset+'_1h_disagg_'+model_dataset+'_'+variable_aemet+'_'+start_time_aux+'_'+end_time_aux+'.nc' #"nn" in the output file name refers to "nearest neighbour"
# #create output directories ir they do not exist.
# if os.path.isdir(dir_rean_disagg) != True:
    # os.makedirs(dir_rean_disagg)
# nc_ca.to_netcdf(savename_disagg)



#bis hierhin

# ##transform hourly ERA5-Land data to from Joule/m^2 per day to W/m^2 per second and rename to rsds, https://confluence.ecmwf.int/pages/viewpage.action?pageId=197702790
# nc_sp[variable]=nc_sp[variable]/3600
# nc_ca[variable]=nc_ca[variable]/3600
# nc_sp = nc_sp[variable].rename(variable_aemet)
# nc_ca = nc_ca[variable].rename(variable_aemet)
# #cacluate daily mean values
# nc_ca = nc_ca.resample(time="D").mean(dim="time")
# nc_sp = nc_sp.resample(time="D").mean(dim="time")

# #load AEMET station data and corresponding metadata
# obsfile = dir_obs+'/'+filename_obs
# nc_obs = xr.open_dataset(obsfile)
# altitude = nc_obs.rsds.location.altitude
# station_name = nc_obs.rsds.location.station_name
# aemet_code = nc_obs.rsds.location.aemet_code
# lat_obs = nc_obs.rsds.location.latitude
# lon_obs = nc_obs.rsds.location.longitude

# #create pandas Datetime indices and retain commmon period
# dates_sp = pd.DatetimeIndex(nc_sp.time.values)
# dates_ca = pd.DatetimeIndex(nc_ca.time.values)
# dates_obs = pd.DatetimeIndex(nc_obs.time.values)

# #check whether reanalysis dates are identical, if yes, use only one date object thereafter (dates_rean)
# if np.all(dates_sp.isin(dates_ca)) != True:
    # raise Exception('ERROR: Reanalysis dates for the two regions SP and CA are not identical !')
# dates_rean = dates_sp
# del(dates_sp,dates_ca)

# #get common time period
# ind_dates_rean = dates_rean.isin(dates_obs)
# ind_dates_obs = dates_obs.isin(dates_rean)
# nc_sp = nc_sp[ind_dates_rean]
# nc_ca = nc_ca[ind_dates_rean]
# dates_rean = dates_rean[ind_dates_rean]
# nc_obs[variable_aemet] = nc_obs.rsds[ind_dates_obs]
# dates_obs = dates_obs[ind_dates_obs]
# nc_sp.values
# nc_ca.values
# nc_obs.values

# # #get nearest neighbour indices
# lat_sp = nc_sp.latitude.values
# lon_sp = nc_sp.longitude.values
# lat_ca = nc_ca.latitude.values
# lon_ca = nc_ca.longitude.values

# #get nearest neighbour values (neighs) from reanalysis
# nanmask_sp = np.transpose(np.isnan(nc_sp.values).sum(axis=0)/nc_sp.values.shape[0])
# nanmask_ca = np.transpose(np.isnan(nc_ca.values).sum(axis=0)/nc_ca.values.shape[0])
# neighs = np.zeros(nc_obs.rsds.shape)
# lat_neighs = np.zeros(nc_obs.rsds.shape[1])
# lon_neighs = np.copy(lat_neighs) 
# for st in np.arange(nc_obs.rsds.shape[1]-58):
    # print('INFO: processing '+nc_obs.location.station_name[st]+'...')
    # #load nearest neighbour reanlaysis data as a function of the domain, either Iberian Peninsula (IB) or Canary Islands (CA)
    # if nc_obs.location.domain[st] == 'IB':
        # #nc_point = nc_sp.sel(latitude=lat_obs[st], longitude=lon_obs[st], method = 'nearest')
        # dist_sp = np.zeros((len(lon_sp),len(lat_sp)))
        # for xx in np.arange(len(lon_sp)):
            # for yy in np.arange(len(lat_sp)):
                # dist_sp[xx,yy] = haversine(lon_obs[st], lat_obs[st], lon_sp[xx], lat_sp[yy])
        # dist_sp[nanmask_sp==1] = np.nan
        # minind = np.where(dist_sp == np.nanmin(dist_sp)) #2d index pointing to nearest grid box in reanalysis that is not entirely nan (i.e. ocean values in ERA5-Land are excluded)
        # nc_point = nc_sp.sel(latitude=lat_sp[minind[1]], longitude=lon_sp[minind[0]])
        # lat_neighs[st] = lat_sp[minind[1]]
        # lon_neighs[st] = lon_sp[minind[0]]
    # elif nc_obs.location.domain[st] == 'CA':
        # #nc_point = nc_ca.sel(latitude=lat_obs[st], longitude=lon_obs[st], method = 'nearest')
        # dist_ca = np.zeros((len(lon_ca),len(lat_ca)))
        # for xx in np.arange(len(lon_ca)):
            # for yy in np.arange(len(lat_ca)):
                # dist_ca[xx,yy] = haversine(lon_obs[st], lat_obs[st], lon_ca[xx], lat_ca[yy])
        # dist_ca[nanmask_ca==1] = np.nan
        # minind = np.where(dist_ca == np.nanmin(dist_ca)) #2d index pointing to nearest grid box in reanalysis that is not entirely nan (i.e. ocean values in ERA5-Land are excluded)
        # nc_point = nc_ca.sel(latitude=lat_ca[minind[1]], longitude=lon_ca[minind[0]])
        # lat_neighs[st] = lat_ca[minind[1]]
        # lon_neighs[st] = lon_ca[minind[0]]
    # else:
        # raise Exception('ERROR: Unknown domain! Please check <location.domain> attibute in the input netCDF file containing AEMET station data !') 
    # neighs[:,st] = nc_point.values.squeeze()
    # nc_point.close()
    # #del nc_point

# nc_sp.close()
# nc_ca.close()

# #create xarray data array
# altitude_neigh = 'Will be filled in future versions'
# station_name_neigh = ['nearest neighbour grid-box corresponding to '+ii for ii in station_name]
# aemet_code_neigh = ['nearest neighbour grid-box corresponding to '+ii for ii in aemet_code]
# source_info = 'This netCDF file contains daily solar radiation time series from '+model_dataset+' provided by Copernicus Data Store.'
# neighs = get_xr_arr(neighs, [dates_rean, np.arange(neighs.shape[1])], variable_aemet, 'global downward shortwave radiation', 'W*m-2', altitude_neigh, station_name_neigh, aemet_code_neigh, lat_neighs, lon_neighs, source_info)
# neighs.attrs['temporal_aggregation'] = 'daily mean data caclulated upon hourly '+variable_aemet+' data from '+str(dates_obs.hour.values.min())+' to '+str(dates_obs.hour.values.min())+ 'o clock'
# start_time = str(dates_obs.min()).replace('-','').replace(' ','').replace(':','')[0:-6]
# end_time = str(dates_obs.max()).replace('-','').replace(' ','').replace(':','')[0:-6]
# savename_neigh = dir_netcdf+'/'+variable_aemet+'_day_'+model_dataset+'_nn_aemet_'+start_time+'_'+end_time+'.nc' #"nn" in the output file name refers to "nearest neighbour"
# neighs.to_netcdf(savename_neigh)

# ##start verification
# obs = nc_obs[variable_aemet]
# ##calculalate hindcast correlation coefficient for the inter-annual seasonal-mean time series (observations vs. ensemble mean) and corresponding p-values based on the effective sample size
# pearson_r = xs.pearson_r(obs,neighs,dim='time',skipna=True).rename('pearson_r')
# pearson_pval = xs.pearson_r_p_value(obs,neighs,dim='time',skipna=True).rename('pearson_pval')
# pearson_pval_effn = xs.pearson_r_eff_p_value(obs,neighs,dim='time',skipna=True).rename('pearson_pval_effn')
# spearman_r = xs.spearman_r(obs,neighs,dim='time',skipna=True).rename('spearman_r')
# spearman_pval = xs.spearman_r_p_value(obs,neighs,dim='time',skipna=True).rename('spearman_pval')
# spearman_pval_effn = xs.spearman_r_eff_p_value(obs,neighs,dim='time',skipna=True).rename('spearman_pval_effn')

# nc_obs.close()
# neighs.close()
# print('INFO: get_neighbour.py has been run successfully !')
